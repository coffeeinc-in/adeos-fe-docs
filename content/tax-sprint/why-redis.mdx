# Why Redis for ADEOS Annotation Processing

## Overview

Redis is the backbone of the ADEOS annotation processing system, providing critical infrastructure for queue management, real-time messaging, and session persistence. This document explains the specific reasons Redis was chosen and how it solves key architectural challenges.

## Core Use Cases in ADEOS

### 1. Queue Management

#### Persistent Job Storage
Redis stores batch jobs that survive server restarts and system failures:

```redis
# Batch queue structure
batches:pending → [batch_job_1, batch_job_2, batch_job_3...]

# Individual batch data
batch_status:abc123 → {
  "batch_id": "abc123",
  "file_id": "doc_456",
  "page_number": 1,
  "status": "processing",
  "created_at": "2024-01-15T10:30:00Z",
  "annotations": [...]
}
```

#### FIFO Queue Operations
Redis provides atomic queue operations essential for batch processing:

```python
# Python backend - Adding jobs to queue
redis.lpush('batches:pending', json.dumps(batch_job))

# Python worker - Processing jobs
batch_data = redis.brpop('batches:pending', timeout=30)
if batch_data:
    process_batch(json.loads(batch_data[1]))
```

#### Processing State Tracking
Per-page and per-file processing states prevent concurrent processing conflicts:

```redis
# Page-specific processing state
processing:doc_456:page_1 → {
  "is_processing": true,
  "batch_id": "abc123",
  "started_at": "2024-01-15T10:30:15Z"
}

# File-wide processing state
processing:doc_456:all_pages → {
  "is_processing": true,
  "batch_id": "xyz789",
  "total_pages": 25,
  "completed_pages": 5
}
```

### 2. Pub/Sub Messaging System

#### Real-time Progress Updates
Redis pub/sub enables instant communication between Python processors and the WebSocket server:

```python
# Python processor publishing progress
redis.publish(f'batch_progress:{batch_id}', json.dumps({
    'type': 'batch_progress',
    'batch_id': batch_id,
    'progress': {
        'completed_items': 3,
        'total_items': 10,
        'percentage': 30
    }
}))
```

```javascript
// Node.js WebSocket server subscribing
redis.subscribe(`batch_progress:${batch_id}`);
redis.on('message', (channel, message) => {
    const data = JSON.parse(message);
    // Route to appropriate WebSocket clients
    broadcastToClients(data);
});
```

#### Channel-based Message Routing
Different message types use dedicated channels for organized communication:

```redis
# Progress updates
batch_progress:abc123 → progress messages

# Completion notifications  
batch_completed:abc123 → completion data

# Error notifications
batch_error:abc123 → error details

# Individual annotation results
annotation_result:ann_456 → extraction results
```

#### Multi-Client Broadcasting
One Redis message can reach multiple WebSocket connections simultaneously:

```javascript
// WebSocket server broadcasting to multiple clients
const message = JSON.parse(redisMessage);
clients.forEach(client => {
    if (client.batchIds.includes(message.batch_id)) {
        client.send(JSON.stringify(message));
    }
});
```

### 3. Session Management

#### Client State Persistence
Redis maintains active batch associations for each client:

```redis
# Active batches per client
client:user123:batches → ["abc123", "def456", "ghi789"]

# Client session data
client:user123:session → {
    "client_id": "user123",
    "connected_at": "2024-01-15T10:25:00Z",
    "last_activity": "2024-01-15T10:45:30Z",
    "active_file_id": "doc_456"
}
```

#### Reconnection Recovery
Clients can retrieve their processing status after disconnection:

```javascript
// Frontend reconnection recovery
const reconnectClient = async (clientId) => {
    const activeBatches = await redis.smembers(`client:${clientId}:batches`);
    
    for (const batchId of activeBatches) {
        const status = await redis.hgetall(`batch_status:${batchId}`);
        if (status.status === 'processing') {
            // Re-subscribe to this batch's updates
            subscribeToWebSocketUpdates(batchId);
        }
    }
};
```

#### Cross-Service Data Sharing
Both Python backend and Node.js WebSocket server access the same Redis data:

```python
# Python backend updating batch status
redis.hset(f'batch_status:{batch_id}', mapping={
    'status': 'completed',
    'completed_at': datetime.utcnow().isoformat(),
    'results_count': len(results)
})
```

```javascript
// Node.js server reading the same data
const batchStatus = await redis.hgetall(`batch_status:${batch_id}`);
if (batchStatus.status === 'completed') {
    notifyClientsOfCompletion(batch_id);
}
```

## Performance Benefits

### 1. In-Memory Speed
- **Sub-millisecond Operations**: Read/write operations complete in under 1ms
- **High Throughput**: Handles thousands of operations per second
- **Low Latency**: Critical for real-time progress updates

### 2. Atomic Operations
Redis atomic operations prevent race conditions in batch processing:

```python
# Atomic increment for progress tracking
redis.hincrby(f'batch_progress:{batch_id}', 'completed_count', 1)

# Atomic batch status updates
with redis.pipeline() as pipe:
    pipe.hset(f'batch_status:{batch_id}', 'status', 'completed')
    pipe.srem(f'client:{client_id}:batches', batch_id)
    pipe.execute()
```

### 3. Built-in Expiration
Automatic cleanup prevents memory bloat:

```python
# Set batch data to expire after 24 hours
redis.setex(f'batch_results:{batch_id}', 86400, json.dumps(results))

# Expire client session data after inactivity
redis.expire(f'client:{client_id}:session', 3600)
```

## Scalability Features

### 1. Redis Cluster Support
- **Horizontal Scaling**: Data distributed across multiple Redis nodes
- **High Availability**: Automatic failover with Redis Sentinel
- **Load Distribution**: Batch processing distributed across cluster nodes

### 2. Memory Optimization
```redis
# Memory-efficient data structures
# Use hashes for structured data
HSET batch:abc123 status processing file_id doc_456 page 1

# Use sets for unique collections
SADD client:user123:batches abc123 def456

# Use lists for ordered queues
LPUSH batches:pending batch_job_data
```

### 3. Connection Pooling
```python
# Python Redis connection pool
redis_pool = redis.ConnectionPool(
    host='redis-server',
    port=6379,
    max_connections=20,
    retry_on_timeout=True
)
redis_client = redis.Redis(connection_pool=redis_pool)
```

## Reliability Features

### 1. Data Persistence
- **RDB Snapshots**: Point-in-time database backups
- **AOF Logging**: Append-only file for durability
- **Hybrid Persistence**: Combination of RDB and AOF for optimal recovery

### 2. Fault Tolerance
```python
# Redis connection with retry logic
def redis_operation_with_retry(operation, max_retries=3):
    for attempt in range(max_retries):
        try:
            return operation()
        except redis.ConnectionError:
            if attempt == max_retries - 1:
                raise
            time.sleep(2 ** attempt)  # Exponential backoff
```

### 3. Backup and Recovery
```bash
# Automated Redis backup
redis-cli --rdb /backup/redis-dump-$(date +%Y%m%d_%H%M%S).rdb

# Point-in-time recovery
redis-server --appendonly yes --appendfsync everysec
```

## Alternative Comparison

### Why Redis over Other Solutions?

#### vs. PostgreSQL
- **Speed**: Redis in-memory operations are 100x faster than disk-based PostgreSQL
- **Pub/Sub**: Native pub/sub support vs. complex PostgreSQL LISTEN/NOTIFY
- **Simplicity**: Simple key-value operations vs. complex SQL queries

#### vs. RabbitMQ
- **Dual Purpose**: Redis serves as both database and message broker
- **Simplicity**: Single service vs. separate queue and storage systems
- **Performance**: Lower latency for simple message routing

#### vs. Apache Kafka
- **Lightweight**: Redis is simpler to deploy and maintain
- **Real-time**: Better suited for real-time updates vs. high-throughput streaming
- **Integration**: Seamless integration with both Python and Node.js

## Monitoring and Observability

### Key Metrics to Track
```bash
# Queue depth monitoring
redis-cli llen batches:pending

# Memory usage tracking  
redis-cli info memory

# Connection monitoring
redis-cli info clients

# Pub/sub activity
redis-cli info replication
```

### Performance Optimization
```python
# Pipeline operations for batch efficiency
with redis.pipeline() as pipe:
    for annotation in annotations:
        pipe.hset(f'annotation:{annotation.id}', mapping=annotation.to_dict())
    pipe.execute()
```

Redis's combination of speed, simplicity, and built-in features makes it the optimal choice for ADEOS's real-time annotation processing architecture, providing the foundation for reliable, scalable, and performant batch processing operations.